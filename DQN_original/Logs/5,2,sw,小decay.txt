>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022295789686567453,
>>> current period 2,
>,-0.0001837827636527342,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.00019033002622011693,
episode 0: ,
overall reward tensor(-0.0646),
overall switching reward tensor(-0.0635),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.00017924909633379964,
episode 1: ,
overall reward tensor(-0.0676),
overall switching reward tensor(-0.0665),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023042707537316784,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00020293813813781293,
>>> current period 4,
>,-0.0001920149939413036,
episode 2: ,
overall reward tensor(-0.0712),
overall switching reward tensor(-0.0701),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002483460889735003,
>>> current period 2,
>,-0.0001837827636527342,
>>> current period 3,
>,-0.00020293813813781293,
>>> current period 4,
>,-0.00019033002622011693,
episode 3: ,
overall reward tensor(-0.0697),
overall switching reward tensor(-0.0686),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00017924909633379964,
episode 4: ,
overall reward tensor(-0.0720),
overall switching reward tensor(-0.0709),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.0001922416352382981,
episode 5: ,
overall reward tensor(-0.0716),
overall switching reward tensor(-0.0705),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023042707537316784,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 6: ,
overall reward tensor(-0.0684),
overall switching reward tensor(-0.0672),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002483460889735003,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00020293813813781293,
>>> current period 4,
>,-0.0001920149939413036,
episode 7: ,
overall reward tensor(-0.0709),
overall switching reward tensor(-0.0698),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 8: ,
overall reward tensor(-0.0574),
overall switching reward tensor(-0.0563),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022295789686567453,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0002174509483970098,
episode 9: ,
overall reward tensor(-0.0638),
overall switching reward tensor(-0.0626),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0002359602525625044,
episode 10: ,
overall reward tensor(-0.0625),
overall switching reward tensor(-0.0613),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023042707537316784,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.0002359602525625044,
episode 11: ,
overall reward tensor(-0.0619),
overall switching reward tensor(-0.0607),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.0001837827636527342,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.00022366330489671422,
episode 12: ,
overall reward tensor(-0.0634),
overall switching reward tensor(-0.0623),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.00022366330489671422,
episode 13: ,
overall reward tensor(-0.0698),
overall switching reward tensor(-0.0687),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0001920149939413036,
episode 14: ,
overall reward tensor(-0.0730),
overall switching reward tensor(-0.0719),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.00019033002622011693,
episode 15: ,
overall reward tensor(-0.0651),
overall switching reward tensor(-0.0639),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021144934919896158,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.00019033002622011693,
episode 16: ,
overall reward tensor(-0.0715),
overall switching reward tensor(-0.0704),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.0002359602525625044,
episode 17: ,
overall reward tensor(-0.0713),
overall switching reward tensor(-0.0701),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0002359602525625044,
episode 18: ,
overall reward tensor(-0.0550),
overall switching reward tensor(-0.0538),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.00018457678222951092,
episode 19: ,
overall reward tensor(-0.0695),
overall switching reward tensor(-0.0684),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.00019033002622011693,
episode 20: ,
overall reward tensor(-0.0657),
overall switching reward tensor(-0.0646),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00017924909633379964,
episode 21: ,
overall reward tensor(-0.0699),
overall switching reward tensor(-0.0688),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0002359602525625044,
episode 22: ,
overall reward tensor(-0.0679),
overall switching reward tensor(-0.0667),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0002359602525625044,
episode 23: ,
overall reward tensor(-0.0568),
overall switching reward tensor(-0.0556),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.00019033002622011693,
episode 24: ,
overall reward tensor(-0.0523),
overall switching reward tensor(-0.0512),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.0002359602525625044,
episode 25: ,
overall reward tensor(-0.0529),
overall switching reward tensor(-0.0518),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018881334944594543,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0002359602525625044,
episode 26: ,
overall reward tensor(-0.0549),
overall switching reward tensor(-0.0537),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023042707537316784,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 27: ,
overall reward tensor(-0.0641),
overall switching reward tensor(-0.0629),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002483460889735003,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 28: ,
overall reward tensor(-0.0576),
overall switching reward tensor(-0.0564),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022295789686567453,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 29: ,
overall reward tensor(-0.0467),
overall switching reward tensor(-0.0455),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 30: ,
overall reward tensor(-0.0498),
overall switching reward tensor(-0.0486),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.0001922416352382981,
episode 31: ,
overall reward tensor(-0.0688),
overall switching reward tensor(-0.0677),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022295789686567453,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.0001922416352382981,
episode 32: ,
overall reward tensor(-0.0676),
overall switching reward tensor(-0.0665),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.0001837827636527342,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001922416352382981,
episode 33: ,
overall reward tensor(-0.0733),
overall switching reward tensor(-0.0722),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.00020293813813781293,
>>> current period 4,
>,-0.0001922416352382981,
episode 34: ,
overall reward tensor(-0.0722),
overall switching reward tensor(-0.0711),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 35: ,
overall reward tensor(-0.0539),
overall switching reward tensor(-0.0528),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018881334944594543,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.0001920149939413036,
episode 36: ,
overall reward tensor(-0.0741),
overall switching reward tensor(-0.0730),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022311888954523775,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00018457678222951092,
episode 37: ,
overall reward tensor(-0.0660),
overall switching reward tensor(-0.0649),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00017924909633379964,
episode 38: ,
overall reward tensor(-0.0678),
overall switching reward tensor(-0.0667),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00025548385646722763,
>>> current period 4,
>,-0.0002174509483970098,
episode 39: ,
overall reward tensor(-0.0702),
overall switching reward tensor(-0.0690),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001920149939413036,
episode 40: ,
overall reward tensor(-0.0581),
overall switching reward tensor(-0.0570),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018881334944594543,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.00019033002622011693,
episode 41: ,
overall reward tensor(-0.0512),
overall switching reward tensor(-0.0502),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.0002174509483970098,
episode 42: ,
overall reward tensor(-0.0674),
overall switching reward tensor(-0.0663),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.00022366330489671422,
episode 43: ,
overall reward tensor(-0.0642),
overall switching reward tensor(-0.0630),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002483460889735003,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00025548385646722763,
>>> current period 4,
>,-0.0002359602525625044,
episode 44: ,
overall reward tensor(-0.0642),
overall switching reward tensor(-0.0630),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0001920149939413036,
episode 45: ,
overall reward tensor(-0.0534),
overall switching reward tensor(-0.0524),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 46: ,
overall reward tensor(-0.0489),
overall switching reward tensor(-0.0478),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.00022366330489671422,
episode 47: ,
overall reward tensor(-0.0647),
overall switching reward tensor(-0.0635),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0001922416352382981,
episode 48: ,
overall reward tensor(-0.0537),
overall switching reward tensor(-0.0526),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.00019033002622011693,
episode 49: ,
overall reward tensor(-0.0519),
overall switching reward tensor(-0.0508),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 50: ,
overall reward tensor(-0.0498),
overall switching reward tensor(-0.0486),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 51: ,
overall reward tensor(-0.0456),
overall switching reward tensor(-0.0445),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00022366330489671422,
episode 52: ,
overall reward tensor(-0.0601),
overall switching reward tensor(-0.0589),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001922416352382981,
episode 53: ,
overall reward tensor(-0.0609),
overall switching reward tensor(-0.0597),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.0001922416352382981,
episode 54: ,
overall reward tensor(-0.0641),
overall switching reward tensor(-0.0630),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0001922416352382981,
episode 55: ,
overall reward tensor(-0.0580),
overall switching reward tensor(-0.0569),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001922416352382981,
episode 56: ,
overall reward tensor(-0.0584),
overall switching reward tensor(-0.0573),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0002359602525625044,
episode 57: ,
overall reward tensor(-0.0560),
overall switching reward tensor(-0.0548),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0001922416352382981,
episode 58: ,
overall reward tensor(-0.0526),
overall switching reward tensor(-0.0514),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0002359602525625044,
episode 59: ,
overall reward tensor(-0.0509),
overall switching reward tensor(-0.0498),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 60: ,
overall reward tensor(-0.0517),
overall switching reward tensor(-0.0505),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.0001922416352382981,
episode 61: ,
overall reward tensor(-0.0568),
overall switching reward tensor(-0.0557),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001920149939413036,
episode 62: ,
overall reward tensor(-0.0624),
overall switching reward tensor(-0.0613),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 63: ,
overall reward tensor(-0.0540),
overall switching reward tensor(-0.0528),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0001922416352382981,
episode 64: ,
overall reward tensor(-0.0413),
overall switching reward tensor(-0.0402),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001920149939413036,
episode 65: ,
overall reward tensor(-0.0579),
overall switching reward tensor(-0.0567),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 66: ,
overall reward tensor(-0.0445),
overall switching reward tensor(-0.0434),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 67: ,
overall reward tensor(-0.0505),
overall switching reward tensor(-0.0494),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002483460889735003,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 68: ,
overall reward tensor(-0.0479),
overall switching reward tensor(-0.0468),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001922416352382981,
episode 69: ,
overall reward tensor(-0.0504),
overall switching reward tensor(-0.0493),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021144934919896158,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 70: ,
overall reward tensor(-0.0620),
overall switching reward tensor(-0.0609),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 71: ,
overall reward tensor(-0.0621),
overall switching reward tensor(-0.0611),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 72: ,
overall reward tensor(-0.0511),
overall switching reward tensor(-0.0500),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 73: ,
overall reward tensor(-0.0586),
overall switching reward tensor(-0.0575),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002483460889735003,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0001922416352382981,
episode 74: ,
overall reward tensor(-0.0463),
overall switching reward tensor(-0.0452),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 75: ,
overall reward tensor(-0.0490),
overall switching reward tensor(-0.0479),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 76: ,
overall reward tensor(-0.0523),
overall switching reward tensor(-0.0512),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022295789686567453,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 77: ,
overall reward tensor(-0.0435),
overall switching reward tensor(-0.0424),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022295789686567453,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001920149939413036,
episode 78: ,
overall reward tensor(-0.0583),
overall switching reward tensor(-0.0572),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002174509483970098,
episode 79: ,
overall reward tensor(-0.0549),
overall switching reward tensor(-0.0538),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 80: ,
overall reward tensor(-0.0406),
overall switching reward tensor(-0.0395),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 81: ,
overall reward tensor(-0.0408),
overall switching reward tensor(-0.0397),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 82: ,
overall reward tensor(-0.0447),
overall switching reward tensor(-0.0436),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021144934919896158,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 83: ,
overall reward tensor(-0.0515),
overall switching reward tensor(-0.0504),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 84: ,
overall reward tensor(-0.0474),
overall switching reward tensor(-0.0462),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001920149939413036,
episode 85: ,
overall reward tensor(-0.0623),
overall switching reward tensor(-0.0612),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 86: ,
overall reward tensor(-0.0482),
overall switching reward tensor(-0.0470),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 87: ,
overall reward tensor(-0.0449),
overall switching reward tensor(-0.0438),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 88: ,
overall reward tensor(-0.0453),
overall switching reward tensor(-0.0442),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 89: ,
overall reward tensor(-0.0460),
overall switching reward tensor(-0.0449),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 90: ,
overall reward tensor(-0.0474),
overall switching reward tensor(-0.0463),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0001922416352382981,
episode 91: ,
overall reward tensor(-0.0419),
overall switching reward tensor(-0.0408),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001922416352382981,
episode 92: ,
overall reward tensor(-0.0473),
overall switching reward tensor(-0.0462),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001922416352382981,
episode 93: ,
overall reward tensor(-0.0462),
overall switching reward tensor(-0.0450),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0001922416352382981,
episode 94: ,
overall reward tensor(-0.0443),
overall switching reward tensor(-0.0433),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001920149939413036,
episode 95: ,
overall reward tensor(-0.0587),
overall switching reward tensor(-0.0576),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 96: ,
overall reward tensor(-0.0539),
overall switching reward tensor(-0.0528),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 97: ,
overall reward tensor(-0.0397),
overall switching reward tensor(-0.0386),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001920149939413036,
episode 98: ,
overall reward tensor(-0.0553),
overall switching reward tensor(-0.0542),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 99: ,
overall reward tensor(-0.0387),
overall switching reward tensor(-0.0376),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 100: ,
overall reward tensor(-0.0390),
overall switching reward tensor(-0.0379),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 101: ,
overall reward tensor(-0.0433),
overall switching reward tensor(-0.0422),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 102: ,
overall reward tensor(-0.0421),
overall switching reward tensor(-0.0410),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 103: ,
overall reward tensor(-0.0418),
overall switching reward tensor(-0.0407),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 104: ,
overall reward tensor(-0.0427),
overall switching reward tensor(-0.0416),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 105: ,
overall reward tensor(-0.0408),
overall switching reward tensor(-0.0397),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 106: ,
overall reward tensor(-0.0415),
overall switching reward tensor(-0.0405),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 107: ,
overall reward tensor(-0.0413),
overall switching reward tensor(-0.0402),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0001922416352382981,
episode 108: ,
overall reward tensor(-0.0404),
overall switching reward tensor(-0.0393),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 109: ,
overall reward tensor(-0.0450),
overall switching reward tensor(-0.0439),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00025548385646722763,
>>> current period 4,
>,-0.0001922416352382981,
episode 110: ,
overall reward tensor(-0.0571),
overall switching reward tensor(-0.0560),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 111: ,
overall reward tensor(-0.0403),
overall switching reward tensor(-0.0392),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001922416352382981,
episode 112: ,
overall reward tensor(-0.0470),
overall switching reward tensor(-0.0459),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 113: ,
overall reward tensor(-0.0458),
overall switching reward tensor(-0.0447),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0002359602525625044,
episode 114: ,
overall reward tensor(-0.0493),
overall switching reward tensor(-0.0482),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.0001922416352382981,
episode 115: ,
overall reward tensor(-0.0522),
overall switching reward tensor(-0.0511),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001920149939413036,
episode 116: ,
overall reward tensor(-0.0560),
overall switching reward tensor(-0.0549),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0001922416352382981,
episode 117: ,
overall reward tensor(-0.0436),
overall switching reward tensor(-0.0425),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 118: ,
overall reward tensor(-0.0413),
overall switching reward tensor(-0.0402),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 119: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002174509483970098,
episode 120: ,
overall reward tensor(-0.0553),
overall switching reward tensor(-0.0541),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 121: ,
overall reward tensor(-0.0406),
overall switching reward tensor(-0.0395),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001920149939413036,
episode 122: ,
overall reward tensor(-0.0531),
overall switching reward tensor(-0.0520),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 123: ,
overall reward tensor(-0.0420),
overall switching reward tensor(-0.0409),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 124: ,
overall reward tensor(-0.0387),
overall switching reward tensor(-0.0376),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 125: ,
overall reward tensor(-0.0412),
overall switching reward tensor(-0.0401),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 126: ,
overall reward tensor(-0.0393),
overall switching reward tensor(-0.0382),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 127: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 128: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 129: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 130: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 131: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 132: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 133: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 134: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 135: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 136: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 137: ,
overall reward tensor(-0.0419),
overall switching reward tensor(-0.0408),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 138: ,
overall reward tensor(-0.0424),
overall switching reward tensor(-0.0413),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 139: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 140: ,
overall reward tensor(-0.0406),
overall switching reward tensor(-0.0395),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 141: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 142: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 143: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 144: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 145: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 146: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 147: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 148: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 149: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 150: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 151: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 152: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 153: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 154: ,
overall reward tensor(-0.0390),
overall switching reward tensor(-0.0379),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 155: ,
overall reward tensor(-0.0426),
overall switching reward tensor(-0.0415),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 156: ,
overall reward tensor(-0.0412),
overall switching reward tensor(-0.0401),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 157: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 158: ,
overall reward tensor(-0.0413),
overall switching reward tensor(-0.0402),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 159: ,
overall reward tensor(-0.0408),
overall switching reward tensor(-0.0397),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 160: ,
overall reward tensor(-0.0391),
overall switching reward tensor(-0.0380),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 161: ,
overall reward tensor(-0.0419),
overall switching reward tensor(-0.0408),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 162: ,
overall reward tensor(-0.0387),
overall switching reward tensor(-0.0376),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 163: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 164: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 165: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 166: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 167: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 168: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 169: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 170: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 171: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 172: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 173: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 174: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 175: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 176: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 177: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 178: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 179: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 180: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 181: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 182: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 183: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 184: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 185: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 186: ,
overall reward tensor(-0.0401),
overall switching reward tensor(-0.0391),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 187: ,
overall reward tensor(-0.0412),
overall switching reward tensor(-0.0401),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 188: ,
overall reward tensor(-0.0406),
overall switching reward tensor(-0.0395),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 189: ,
overall reward tensor(-0.0412),
overall switching reward tensor(-0.0401),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 190: ,
overall reward tensor(-0.0417),
overall switching reward tensor(-0.0406),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 191: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 192: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 193: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 194: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 195: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 196: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 197: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 198: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 199: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 200: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 201: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 202: ,
overall reward tensor(-0.0419),
overall switching reward tensor(-0.0408),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 203: ,
overall reward tensor(-0.0423),
overall switching reward tensor(-0.0412),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 204: ,
overall reward tensor(-0.0404),
overall switching reward tensor(-0.0393),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 205: ,
overall reward tensor(-0.0414),
overall switching reward tensor(-0.0403),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 206: ,
overall reward tensor(-0.0387),
overall switching reward tensor(-0.0376),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 207: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 208: ,
overall reward tensor(-0.0412),
overall switching reward tensor(-0.0401),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 209: ,
overall reward tensor(-0.0423),
overall switching reward tensor(-0.0413),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 210: ,
overall reward tensor(-0.0394),
overall switching reward tensor(-0.0383),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 211: ,
overall reward tensor(-0.0452),
overall switching reward tensor(-0.0441),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 212: ,
overall reward tensor(-0.0407),
overall switching reward tensor(-0.0396),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 213: ,
overall reward tensor(-0.0426),
overall switching reward tensor(-0.0415),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 214: ,
overall reward tensor(-0.0406),
overall switching reward tensor(-0.0395),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 215: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 216: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 217: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 218: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 219: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 220: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 221: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 222: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 223: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 224: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 225: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 226: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 227: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 228: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 229: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 230: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 231: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 232: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 233: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 234: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 235: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001920149939413036,
episode 236: ,
overall reward tensor(-0.0514),
overall switching reward tensor(-0.0503),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 237: ,
overall reward tensor(-0.0457),
overall switching reward tensor(-0.0446),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 238: ,
overall reward tensor(-0.0412),
overall switching reward tensor(-0.0401),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 239: ,
overall reward tensor(-0.0418),
overall switching reward tensor(-0.0407),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 240: ,
overall reward tensor(-0.0407),
overall switching reward tensor(-0.0396),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 241: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 242: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 243: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 244: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 245: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 246: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 247: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 248: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 249: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 250: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 251: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 252: ,
overall reward tensor(-0.0387),
overall switching reward tensor(-0.0376),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 253: ,
overall reward tensor(-0.0407),
overall switching reward tensor(-0.0396),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 254: ,
overall reward tensor(-0.0388),
overall switching reward tensor(-0.0377),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 255: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 256: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 257: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 258: ,
overall reward tensor(-0.0406),
overall switching reward tensor(-0.0395),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0001922416352382981,
episode 259: ,
overall reward tensor(-0.0418),
overall switching reward tensor(-0.0407),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001920149939413036,
episode 260: ,
overall reward tensor(-0.0516),
overall switching reward tensor(-0.0505),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 261: ,
overall reward tensor(-0.0443),
overall switching reward tensor(-0.0432),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001920149939413036,
episode 262: ,
overall reward tensor(-0.0519),
overall switching reward tensor(-0.0508),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 263: ,
overall reward tensor(-0.0471),
overall switching reward tensor(-0.0460),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 264: ,
overall reward tensor(-0.0393),
overall switching reward tensor(-0.0382),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 265: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 266: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 267: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 268: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 269: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 270: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 271: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 272: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 273: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 274: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 275: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 276: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 277: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 278: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 279: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 280: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 281: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 282: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 283: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 284: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 285: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 286: ,
overall reward tensor(-0.0380),
overall switching reward tensor(-0.0369),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 287: ,
overall reward tensor(-0.0426),
overall switching reward tensor(-0.0415),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 288: ,
overall reward tensor(-0.0393),
overall switching reward tensor(-0.0382),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 289: ,
overall reward tensor(-0.0412),
overall switching reward tensor(-0.0401),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 290: ,
overall reward tensor(-0.0416),
overall switching reward tensor(-0.0405),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 291: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 292: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 293: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 294: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 295: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 296: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 297: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 298: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 299: ,
overall reward tensor(-0.0400),
overall switching reward tensor(-0.0389),
