>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002359639824033819,
>>> current period 2,
>,-0.0002658792934829883,
>>> current period 3,
>,-0.0002969101422733784,
>>> current period 4,
>,-0.0002488133424287603,
episode 0: ,
overall reward tensor(-0.1636),
overall switching reward tensor(-0.1623),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028386409674056764,
>>> current period 2,
>,-0.00023685299600294832,
>>> current period 3,
>,-0.00026669485876776647,
>>> current period 4,
>,-0.00029004098815891204,
episode 1: ,
overall reward tensor(-0.1695),
overall switching reward tensor(-0.1682),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00025690202516736834,
>>> current period 2,
>,-0.00023840986389927487,
>>> current period 3,
>,-0.00030227107455148034,
>>> current period 4,
>,-0.00024072366353489045,
episode 2: ,
overall reward tensor(-0.1531),
overall switching reward tensor(-0.1518),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002794675172067482,
>>> current period 2,
>,-0.00028605122915065695,
>>> current period 3,
>,-0.00026469043033969475,
>>> current period 4,
>,-0.0002365814442338956,
episode 3: ,
overall reward tensor(-0.1632),
overall switching reward tensor(-0.1619),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022333441999661293,
>>> current period 2,
>,-0.0002714828828619645,
>>> current period 3,
>,-0.00025908473099760536,
>>> current period 4,
>,-0.0003096049070915711,
episode 4: ,
overall reward tensor(-0.1562),
overall switching reward tensor(-0.1549),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026798665487266543,
>>> current period 2,
>,-0.00027609416713728416,
>>> current period 3,
>,-0.0002796767360639084,
>>> current period 4,
>,-0.0002715703764569174,
episode 5: ,
overall reward tensor(-0.1605),
overall switching reward tensor(-0.1592),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026506607071794913,
>>> current period 2,
>,-0.00026162936735929103,
>>> current period 3,
>,-0.0003054105319213036,
>>> current period 4,
>,-0.00029301806651059334,
episode 6: ,
overall reward tensor(-0.1767),
overall switching reward tensor(-0.1753),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002866983057534431,
>>> current period 2,
>,-0.0002302982995352167,
>>> current period 3,
>,-0.00027353236753627414,
>>> current period 4,
>,-0.00023735070587706816,
episode 7: ,
overall reward tensor(-0.1518),
overall switching reward tensor(-0.1506),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00025339556756432216,
>>> current period 2,
>,-0.0002741394072306677,
>>> current period 3,
>,-0.0002991311325007457,
>>> current period 4,
>,-0.0002777565967665465,
episode 8: ,
overall reward tensor(-0.1617),
overall switching reward tensor(-0.1603),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023437850716490858,
>>> current period 2,
>,-0.0002210654016545322,
>>> current period 3,
>,-0.0002574454104379399,
>>> current period 4,
>,-0.00024015897746127964,
episode 9: ,
overall reward tensor(-0.1654),
overall switching reward tensor(-0.1642),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024410932896807384,
>>> current period 2,
>,-0.0002663975122958271,
>>> current period 3,
>,-0.0002649704012648305,
>>> current period 4,
>,-0.0002989607055836868,
episode 10: ,
overall reward tensor(-0.1633),
overall switching reward tensor(-0.1620),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023961321708406956,
>>> current period 2,
>,-0.0002765256404489886,
>>> current period 3,
>,-0.00030781990449169414,
>>> current period 4,
>,-0.00029359310449031715,
episode 11: ,
overall reward tensor(-0.1680),
overall switching reward tensor(-0.1666),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00027516160242228274,
>>> current period 2,
>,-0.0002589852619020793,
>>> current period 3,
>,-0.0002806612829137526,
>>> current period 4,
>,-0.0002260893165994667,
episode 12: ,
overall reward tensor(-0.1677),
overall switching reward tensor(-0.1664),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002176032808620008,
>>> current period 2,
>,-0.00023250858557441806,
>>> current period 3,
>,-0.0003089966722845337,
>>> current period 4,
>,-0.0002598400540481145,
episode 13: ,
overall reward tensor(-0.1696),
overall switching reward tensor(-0.1684),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000262207789685779,
>>> current period 2,
>,-0.0002543199172595539,
>>> current period 3,
>,-0.00025459345397296133,
>>> current period 4,
>,-0.0002500255663932873,
episode 14: ,
overall reward tensor(-0.1562),
overall switching reward tensor(-0.1549),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00021706193213023232,
>>> current period 2,
>,-0.00022025493479983866,
>>> current period 3,
>,-0.0002768492935044147,
>>> current period 4,
>,-0.00028235814317436486,
episode 15: ,
overall reward tensor(-0.1505),
overall switching reward tensor(-0.1493),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000306791833810356,
>>> current period 2,
>,-0.0002497325507240616,
>>> current period 3,
>,-0.0002787753016315314,
>>> current period 4,
>,-0.0002365513925237926,
episode 16: ,
overall reward tensor(-0.1692),
overall switching reward tensor(-0.1679),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022418661329813078,
>>> current period 2,
>,-0.0002749865113416302,
>>> current period 3,
>,-0.00026748953654645867,
>>> current period 4,
>,-0.0002683262002603764,
episode 17: ,
overall reward tensor(-0.1658),
overall switching reward tensor(-0.1646),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00021652178052456367,
>>> current period 2,
>,-0.0002487264583836017,
>>> current period 3,
>,-0.0002991311325007457,
>>> current period 4,
>,-0.0002925570234092567,
episode 18: ,
overall reward tensor(-0.1688),
overall switching reward tensor(-0.1675),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002551882406045115,
>>> current period 2,
>,-0.0002517780544694306,
>>> current period 3,
>,-0.0002739790831903815,
>>> current period 4,
>,-0.00024108040708566172,
episode 19: ,
overall reward tensor(-0.1499),
overall switching reward tensor(-0.1486),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024180954309903368,
>>> current period 2,
>,-0.00022189761828871494,
>>> current period 3,
>,-0.00029253978847606517,
>>> current period 4,
>,-0.00030819545833442156,
episode 20: ,
overall reward tensor(-0.1548),
overall switching reward tensor(-0.1535),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000295275256796346,
>>> current period 2,
>,-0.00021469745206251667,
>>> current period 3,
>,-0.00027582938622713546,
>>> current period 4,
>,-0.00026260869732572077,
episode 21: ,
overall reward tensor(-0.1571),
overall switching reward tensor(-0.1558),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002555449243005162,
>>> current period 2,
>,-0.00028982943685720305,
>>> current period 3,
>,-0.0002744323238845517,
>>> current period 4,
>,-0.0002451416874085656,
episode 22: ,
overall reward tensor(-0.1585),
overall switching reward tensor(-0.1572),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023852003934982249,
>>> current period 2,
>,-0.0002724200939249918,
>>> current period 3,
>,-0.00029602783689150133,
>>> current period 4,
>,-0.00028054179653216893,
episode 23: ,
overall reward tensor(-0.1538),
overall switching reward tensor(-0.1524),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002908950324336819,
>>> current period 2,
>,-0.00026910753836980206,
>>> current period 3,
>,-0.00023110669569498246,
>>> current period 4,
>,-0.00022986804524590445,
episode 24: ,
overall reward tensor(-0.1548),
overall switching reward tensor(-0.1536),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024801073110419986,
>>> current period 2,
>,-0.0002306174830392647,
>>> current period 3,
>,-0.00030621552800417216,
>>> current period 4,
>,-0.00029093047787862107,
episode 25: ,
overall reward tensor(-0.1444),
overall switching reward tensor(-0.1431),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00021883102725224032,
>>> current period 2,
>,-0.00022500435373530437,
>>> current period 3,
>,-0.00028468670903217816,
>>> current period 4,
>,-0.00022245412493302746,
episode 26: ,
overall reward tensor(-0.1592),
overall switching reward tensor(-0.1580),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023384381685066539,
>>> current period 2,
>,-0.00027891771123644815,
>>> current period 3,
>,-0.0002288453716487381,
>>> current period 4,
>,-0.00026097656572214307,
episode 27: ,
overall reward tensor(-0.1468),
overall switching reward tensor(-0.1456),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00025339556686196515,
>>> current period 2,
>,-0.00023271901013210486,
>>> current period 3,
>,-0.00028347204591567724,
>>> current period 4,
>,-0.00024520186073042597,
episode 28: ,
overall reward tensor(-0.1614),
overall switching reward tensor(-0.1601),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026673979700894235,
>>> current period 2,
>,-0.00027082116589200204,
>>> current period 3,
>,-0.00024347366112065593,
>>> current period 4,
>,-0.00022429167756111466,
episode 29: ,
overall reward tensor(-0.1519),
overall switching reward tensor(-0.1507),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00021882532021691163,
>>> current period 2,
>,-0.0002594431082398303,
>>> current period 3,
>,-0.0002607847388280031,
>>> current period 4,
>,-0.0003070302774565756,
episode 30: ,
overall reward tensor(-0.1605),
overall switching reward tensor(-0.1592),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000216521780087547,
>>> current period 2,
>,-0.00023648770605836365,
>>> current period 3,
>,-0.0002863455963319087,
>>> current period 4,
>,-0.00024307430414343634,
episode 31: ,
overall reward tensor(-0.1524),
overall switching reward tensor(-0.1512),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000241697941190782,
>>> current period 2,
>,-0.0002612319967094462,
>>> current period 3,
>,-0.00027121513429638326,
>>> current period 4,
>,-0.00024025152144581041,
episode 32: ,
overall reward tensor(-0.1716),
overall switching reward tensor(-0.1703),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022413532471454243,
>>> current period 2,
>,-0.00024313403643293148,
>>> current period 3,
>,-0.000265872514142278,
>>> current period 4,
>,-0.000261674269181018,
episode 33: ,
overall reward tensor(-0.1556),
overall switching reward tensor(-0.1544),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003063780402940971,
>>> current period 2,
>,-0.0002653899943146541,
>>> current period 3,
>,-0.0002614733450866976,
>>> current period 4,
>,-0.000246692378967653,
episode 34: ,
overall reward tensor(-0.1694),
overall switching reward tensor(-0.1681),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002661986619888319,
>>> current period 2,
>,-0.00022431482516149754,
>>> current period 3,
>,-0.00030029355284194305,
>>> current period 4,
>,-0.00027583621759806024,
episode 35: ,
overall reward tensor(-0.1438),
overall switching reward tensor(-0.1425),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00025753211881572444,
>>> current period 2,
>,-0.0002808272068877673,
>>> current period 3,
>,-0.00028912294544198637,
>>> current period 4,
>,-0.0002415389496132875,
episode 36: ,
overall reward tensor(-0.1620),
overall switching reward tensor(-0.1607),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003064802024259364,
>>> current period 2,
>,-0.0002746541820246926,
>>> current period 3,
>,-0.0002798493481553081,
>>> current period 4,
>,-0.0002660250054464336,
episode 37: ,
overall reward tensor(-0.1556),
overall switching reward tensor(-0.1543),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002480651968611969,
>>> current period 2,
>,-0.00022374460099410106,
>>> current period 3,
>,-0.00026850488548113826,
>>> current period 4,
>,-0.00026808936612154655,
episode 38: ,
overall reward tensor(-0.1675),
overall switching reward tensor(-0.1662),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002813776776960194,
>>> current period 2,
>,-0.00026130538876478727,
>>> current period 3,
>,-0.0002746840773960703,
>>> current period 4,
>,-0.0002600982332933409,
episode 39: ,
overall reward tensor(-0.1668),
overall switching reward tensor(-0.1655),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00025221000533244645,
>>> current period 2,
>,-0.00023210726426524706,
>>> current period 3,
>,-0.0003133000978063905,
>>> current period 4,
>,-0.00024282347952736915,
episode 40: ,
overall reward tensor(-0.1596),
overall switching reward tensor(-0.1583),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002707139629430834,
>>> current period 2,
>,-0.0002686878525079781,
>>> current period 3,
>,-0.00025930979577545583,
>>> current period 4,
>,-0.00028954736113472024,
episode 41: ,
overall reward tensor(-0.1457),
overall switching reward tensor(-0.1444),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002833608828665988,
>>> current period 2,
>,-0.0002737144519042095,
>>> current period 3,
>,-0.0002901988246051951,
>>> current period 4,
>,-0.00023279123752348622,
episode 42: ,
overall reward tensor(-0.1519),
overall switching reward tensor(-0.1506),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00032263390978566115,
>>> current period 2,
>,-0.0002614918056228728,
>>> current period 3,
>,-0.00025843744871868626,
>>> current period 4,
>,-0.00026970042883168695,
episode 43: ,
overall reward tensor(-0.1544),
overall switching reward tensor(-0.1531),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023695867819493451,
>>> current period 2,
>,-0.0002269084568471404,
>>> current period 3,
>,-0.00026867929686821444,
>>> current period 4,
>,-0.00027075215267827787,
episode 44: ,
overall reward tensor(-0.1496),
overall switching reward tensor(-0.1484),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024306013193476348,
>>> current period 2,
>,-0.0002809383856912781,
>>> current period 3,
>,-0.00025151606320520666,
>>> current period 4,
>,-0.00026140665890731266,
episode 45: ,
overall reward tensor(-0.1629),
overall switching reward tensor(-0.1616),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00021945656093326816,
>>> current period 2,
>,-0.00022332082234435415,
>>> current period 3,
>,-0.00030590798182266425,
>>> current period 4,
>,-0.00025402527731675534,
episode 46: ,
overall reward tensor(-0.1524),
overall switching reward tensor(-0.1511),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026673979700894235,
>>> current period 2,
>,-0.00026242594662118324,
>>> current period 3,
>,-0.00028282996945414236,
>>> current period 4,
>,-0.00027673327945309986,
episode 47: ,
overall reward tensor(-0.1420),
overall switching reward tensor(-0.1407),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002709893823508738,
>>> current period 2,
>,-0.00027375209134072463,
>>> current period 3,
>,-0.0002665894613299255,
>>> current period 4,
>,-0.0002461972046297658,
episode 48: ,
overall reward tensor(-0.1449),
overall switching reward tensor(-0.1436),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00021652178002420618,
>>> current period 2,
>,-0.0002572948153344852,
>>> current period 3,
>,-0.0002681333699178597,
>>> current period 4,
>,-0.00026995861610703994,
episode 49: ,
overall reward tensor(-0.1411),
overall switching reward tensor(-0.1399),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002592337844026062,
>>> current period 2,
>,-0.00025288445399392995,
>>> current period 3,
>,-0.0002732221730875339,
>>> current period 4,
>,-0.00026513214323344464,
episode 50: ,
overall reward tensor(-0.1655),
overall switching reward tensor(-0.1642),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022240094626514348,
>>> current period 2,
>,-0.00021669465827936558,
>>> current period 3,
>,-0.00034434096255168007,
>>> current period 4,
>,-0.00030310282833432233,
episode 51: ,
overall reward tensor(-0.1570),
overall switching reward tensor(-0.1556),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003151918108989151,
>>> current period 2,
>,-0.00026766122389954895,
>>> current period 3,
>,-0.00028933080235358296,
>>> current period 4,
>,-0.00024108729726610446,
episode 52: ,
overall reward tensor(-0.1645),
overall switching reward tensor(-0.1631),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002166707518721211,
>>> current period 2,
>,-0.00022132421368790758,
>>> current period 3,
>,-0.00026404603873129105,
>>> current period 4,
>,-0.0002974074922143076,
episode 53: ,
overall reward tensor(-0.1577),
overall switching reward tensor(-0.1565),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002794675169414078,
>>> current period 2,
>,-0.00026782189602325473,
>>> current period 3,
>,-0.00026043983017367184,
>>> current period 4,
>,-0.0002772347254624457,
episode 54: ,
overall reward tensor(-0.1435),
overall switching reward tensor(-0.1422),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000262207789685779,
>>> current period 2,
>,-0.0002766298305856618,
>>> current period 3,
>,-0.00027434346648195655,
>>> current period 4,
>,-0.0002739739854186707,
episode 55: ,
overall reward tensor(-0.1514),
overall switching reward tensor(-0.1501),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022569396591107515,
>>> current period 2,
>,-0.00024709656618141336,
>>> current period 3,
>,-0.0003012955524332717,
>>> current period 4,
>,-0.00028730684637433274,
episode 56: ,
overall reward tensor(-0.1595),
overall switching reward tensor(-0.1582),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003070822677692181,
>>> current period 2,
>,-0.00025772215852351235,
>>> current period 3,
>,-0.00026422943850196975,
>>> current period 4,
>,-0.0002319553694531102,
episode 57: ,
overall reward tensor(-0.1559),
overall switching reward tensor(-0.1546),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000267287109709705,
>>> current period 2,
>,-0.00023760932808960177,
>>> current period 3,
>,-0.0002479038616473758,
>>> current period 4,
>,-0.0002652582119476826,
episode 58: ,
overall reward tensor(-0.1662),
overall switching reward tensor(-0.1649),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024557934329448616,
>>> current period 2,
>,-0.00023841348067317266,
>>> current period 3,
>,-0.00025074838520234335,
>>> current period 4,
>,-0.0002402161199463794,
episode 59: ,
overall reward tensor(-0.1589),
overall switching reward tensor(-0.1577),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002206278894922115,
>>> current period 2,
>,-0.00025492648606546234,
>>> current period 3,
>,-0.0003033582864628857,
>>> current period 4,
>,-0.00022744289035678058,
episode 60: ,
overall reward tensor(-0.1618),
overall switching reward tensor(-0.1605),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023316070825474852,
>>> current period 2,
>,-0.00025788617554632783,
>>> current period 3,
>,-0.0003025848374316722,
>>> current period 4,
>,-0.000303962977799288,
episode 61: ,
overall reward tensor(-0.1572),
overall switching reward tensor(-0.1559),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002813776776960194,
>>> current period 2,
>,-0.00021836135761582595,
>>> current period 3,
>,-0.0002669455336777434,
>>> current period 4,
>,-0.00023096677043724865,
episode 62: ,
overall reward tensor(-0.1718),
overall switching reward tensor(-0.1706),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002831156106840493,
>>> current period 2,
>,-0.0002475310007500138,
>>> current period 3,
>,-0.0002806684190549934,
>>> current period 4,
>,-0.00026710907464574284,
episode 63: ,
overall reward tensor(-0.1538),
overall switching reward tensor(-0.1525),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024524941839480633,
>>> current period 2,
>,-0.0002250043509161592,
>>> current period 3,
>,-0.00028075200264592227,
>>> current period 4,
>,-0.00023049790174133657,
episode 64: ,
overall reward tensor(-0.1561),
overall switching reward tensor(-0.1549),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024983126035549216,
>>> current period 2,
>,-0.00027723895172919954,
>>> current period 3,
>,-0.00027088071329486846,
>>> current period 4,
>,-0.0002835439288986199,
episode 65: ,
overall reward tensor(-0.1510),
overall switching reward tensor(-0.1497),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002367724477242953,
>>> current period 2,
>,-0.00022777764102708457,
>>> current period 3,
>,-0.000272450668001783,
>>> current period 4,
>,-0.0002661251400477346,
episode 66: ,
overall reward tensor(-0.1461),
overall switching reward tensor(-0.1448),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024332197192097823,
>>> current period 2,
>,-0.0002737144519042095,
>>> current period 3,
>,-0.0003040572288023906,
>>> current period 4,
>,-0.0002564741130490402,
episode 67: ,
overall reward tensor(-0.1650),
overall switching reward tensor(-0.1637),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000219130553404752,
>>> current period 2,
>,-0.00028473310564378036,
>>> current period 3,
>,-0.00029092389252034274,
>>> current period 4,
>,-0.00024211624999625117,
episode 68: ,
overall reward tensor(-0.1643),
overall switching reward tensor(-0.1631),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002362190258997456,
>>> current period 2,
>,-0.00025189888671910837,
>>> current period 3,
>,-0.00027994526944474427,
>>> current period 4,
>,-0.000265905625140411,
episode 69: ,
overall reward tensor(-0.1580),
overall switching reward tensor(-0.1567),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024136499438760648,
>>> current period 2,
>,-0.00022705551273821017,
>>> current period 3,
>,-0.0003012955524332717,
>>> current period 4,
>,-0.0002911940945096465,
episode 70: ,
overall reward tensor(-0.1620),
overall switching reward tensor(-0.1607),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00021945656093326816,
>>> current period 2,
>,-0.00024239784675356534,
>>> current period 3,
>,-0.00026933851422249595,
>>> current period 4,
>,-0.00024772232042631425,
episode 71: ,
overall reward tensor(-0.1856),
overall switching reward tensor(-0.1843),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002401968359001722,
>>> current period 2,
>,-0.00023139220597307374,
>>> current period 3,
>,-0.0002819910701289322,
>>> current period 4,
>,-0.00023117350542425328,
episode 72: ,
overall reward tensor(-0.1681),
overall switching reward tensor(-0.1669),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00029046209199310206,
>>> current period 2,
>,-0.00027522384291829333,
>>> current period 3,
>,-0.00028890835010687117,
>>> current period 4,
>,-0.00022576792203914402,
episode 73: ,
overall reward tensor(-0.1517),
overall switching reward tensor(-0.1504),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00029689432383537504,
>>> current period 2,
>,-0.00022525021506490753,
>>> current period 3,
>,-0.00023814519817998053,
>>> current period 4,
>,-0.00022824409557343809,
episode 74: ,
overall reward tensor(-0.1613),
overall switching reward tensor(-0.1601),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002477101654019421,
>>> current period 2,
>,-0.00027694163250027736,
>>> current period 3,
>,-0.00026175376081435074,
>>> current period 4,
>,-0.0002932549690665943,
episode 75: ,
overall reward tensor(-0.1560),
overall switching reward tensor(-0.1547),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023012717559227878,
>>> current period 2,
>,-0.0002631863000527936,
>>> current period 3,
>,-0.00028720932506095517,
>>> current period 4,
>,-0.00028512912872007313,
episode 76: ,
overall reward tensor(-0.1392),
overall switching reward tensor(-0.1379),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002552190782031826,
>>> current period 2,
>,-0.0002720153094283052,
>>> current period 3,
>,-0.00024236269127225752,
>>> current period 4,
>,-0.00027972946778602757,
episode 77: ,
overall reward tensor(-0.1713),
overall switching reward tensor(-0.1700),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002922643959375078,
>>> current period 2,
>,-0.00023238524800380924,
>>> current period 3,
>,-0.0003089966722845337,
>>> current period 4,
>,-0.00028475189719774185,
episode 78: ,
overall reward tensor(-0.1484),
overall switching reward tensor(-0.1470),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002902388605944159,
>>> current period 2,
>,-0.0002740561894254942,
>>> current period 3,
>,-0.00028169741501349923,
>>> current period 4,
>,-0.00025785414023710206,
episode 79: ,
overall reward tensor(-0.1702),
overall switching reward tensor(-0.1689),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00029683813197971997,
>>> current period 2,
>,-0.0002609587180686492,
>>> current period 3,
>,-0.0002994733375646275,
>>> current period 4,
>,-0.0002835439288986199,
episode 80: ,
overall reward tensor(-0.1603),
overall switching reward tensor(-0.1589),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000262092410859214,
>>> current period 2,
>,-0.00022345810601235674,
>>> current period 3,
>,-0.00026622277211231255,
>>> current period 4,
>,-0.00026989588073442536,
episode 81: ,
overall reward tensor(-0.1756),
overall switching reward tensor(-0.1743),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00029620475714072376,
>>> current period 2,
>,-0.00024170749107114696,
>>> current period 3,
>,-0.00026509905252689237,
>>> current period 4,
>,-0.0003078326263018283,
episode 82: ,
overall reward tensor(-0.1455),
overall switching reward tensor(-0.1442),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00021612415115215583,
>>> current period 2,
>,-0.00023368670860130842,
>>> current period 3,
>,-0.0002288453716487381,
>>> current period 4,
>,-0.0002715703764569174,
episode 83: ,
overall reward tensor(-0.1519),
overall switching reward tensor(-0.1507),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023836343091722484,
>>> current period 2,
>,-0.0002463052703704482,
>>> current period 3,
>,-0.0002594474686897314,
>>> current period 4,
>,-0.0002813470089591505,
episode 84: ,
overall reward tensor(-0.1547),
overall switching reward tensor(-0.1534),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002762873412920053,
>>> current period 2,
>,-0.00026868785219480266,
>>> current period 3,
>,-0.000265872514142278,
>>> current period 4,
>,-0.0002840419548407899,
episode 85: ,
overall reward tensor(-0.1567),
overall switching reward tensor(-0.1554),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026673979700894235,
>>> current period 2,
>,-0.0002590847012395634,
>>> current period 3,
>,-0.00026534742038629433,
>>> current period 4,
>,-0.00025252639565431724,
episode 86: ,
overall reward tensor(-0.1603),
overall switching reward tensor(-0.1590),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002592337844026062,
>>> current period 2,
>,-0.00022185486024905456,
>>> current period 3,
>,-0.0003519609695459122,
>>> current period 4,
>,-0.0002766639858402385,
episode 87: ,
overall reward tensor(-0.1661),
overall switching reward tensor(-0.1648),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00029127489342944637,
>>> current period 2,
>,-0.0002679785578059967,
>>> current period 3,
>,-0.0002667824598302073,
>>> current period 4,
>,-0.00028018757357275244,
episode 88: ,
overall reward tensor(-0.1514),
overall switching reward tensor(-0.1501),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00025322094095371037,
>>> current period 2,
>,-0.0002445968399568687,
>>> current period 3,
>,-0.00026617856478749227,
>>> current period 4,
>,-0.0002899615615362243,
episode 89: ,
overall reward tensor(-0.1533),
overall switching reward tensor(-0.1520),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00025786599153014144,
>>> current period 2,
>,-0.00025180089093931434,
>>> current period 3,
>,-0.0002896210501910766,
>>> current period 4,
>,-0.00028717054937649276,
episode 90: ,
overall reward tensor(-0.1647),
overall switching reward tensor(-0.1634),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003063780402940971,
>>> current period 2,
>,-0.0002424994228471764,
>>> current period 3,
>,-0.0002593177224077083,
>>> current period 4,
>,-0.00022286838824984987,
episode 91: ,
overall reward tensor(-0.1776),
overall switching reward tensor(-0.1763),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002438460973935118,
>>> current period 2,
>,-0.0002552027528273369,
>>> current period 3,
>,-0.0002997110354614034,
>>> current period 4,
>,-0.0002776600257703959,
episode 92: ,
overall reward tensor(-0.1712),
overall switching reward tensor(-0.1698),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000264799268973733,
>>> current period 2,
>,-0.0002629551009944742,
>>> current period 3,
>,-0.00027591447410024695,
>>> current period 4,
>,-0.00024199415963246888,
episode 93: ,
overall reward tensor(-0.1476),
overall switching reward tensor(-0.1464),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022244970056722424,
>>> current period 2,
>,-0.0002650127179660171,
>>> current period 3,
>,-0.000253274339654308,
>>> current period 4,
>,-0.0002641683394328549,
episode 94: ,
overall reward tensor(-0.1465),
overall switching reward tensor(-0.1452),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026600205416035913,
>>> current period 2,
>,-0.00022603833046242874,
>>> current period 3,
>,-0.0002753963607016108,
>>> current period 4,
>,-0.00027258626064257773,
episode 95: ,
overall reward tensor(-0.1580),
overall switching reward tensor(-0.1567),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002838931208778724,
>>> current period 2,
>,-0.00027023763678105366,
>>> current period 3,
>,-0.00025817907918516015,
>>> current period 4,
>,-0.00023799058925642766,
episode 96: ,
overall reward tensor(-0.1535),
overall switching reward tensor(-0.1522),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003030329551959349,
>>> current period 2,
>,-0.0002732956083229608,
>>> current period 3,
>,-0.0002636872200382586,
>>> current period 4,
>,-0.0002550947368541139,
episode 97: ,
overall reward tensor(-0.1747),
overall switching reward tensor(-0.1733),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002653477946817435,
>>> current period 2,
>,-0.00022509976461739336,
>>> current period 3,
>,-0.0002850302719564444,
>>> current period 4,
>,-0.00026470674903139775,
episode 98: ,
overall reward tensor(-0.1514),
overall switching reward tensor(-0.1501),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002868147241584801,
>>> current period 2,
>,-0.0002515626723734224,
>>> current period 3,
>,-0.00027491064059872625,
>>> current period 4,
>,-0.0002581816716556866,
episode 99: ,
overall reward tensor(-0.1775),
overall switching reward tensor(-0.1762),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00030585193178635564,
>>> current period 2,
>,-0.00026514437819093363,
>>> current period 3,
>,-0.00029520786146638734,
>>> current period 4,
>,-0.000277217212693315,
episode 100: ,
overall reward tensor(-0.1469),
overall switching reward tensor(-0.1455),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002435910557506268,
>>> current period 2,
>,-0.00027767267675203887,
>>> current period 3,
>,-0.0002444031927620226,
>>> current period 4,
>,-0.0003061359840860052,
episode 101: ,
overall reward tensor(-0.1605),
overall switching reward tensor(-0.1592),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026935089167164674,
>>> current period 2,
>,-0.00025169028757738345,
>>> current period 3,
>,-0.00027368285926024106,
>>> current period 4,
>,-0.00026912631340457005,
episode 102: ,
overall reward tensor(-0.1786),
overall switching reward tensor(-0.1773),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00031405700271339653,
>>> current period 2,
>,-0.0002745213334397529,
>>> current period 3,
>,-0.00026505130598181154,
>>> current period 4,
>,-0.0002779116033636142,
episode 103: ,
overall reward tensor(-0.1624),
overall switching reward tensor(-0.1610),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00031036655400608625,
>>> current period 2,
>,-0.00027049183407826515,
>>> current period 3,
>,-0.00025885535898191104,
>>> current period 4,
>,-0.0002511431136283698,
episode 104: ,
overall reward tensor(-0.1635),
overall switching reward tensor(-0.1621),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026565954992938617,
>>> current period 2,
>,-0.0002636024535036669,
>>> current period 3,
>,-0.0002687639715394939,
>>> current period 4,
>,-0.00023569719148680058,
episode 105: ,
overall reward tensor(-0.1610),
overall switching reward tensor(-0.1597),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00029821005237470015,
>>> current period 2,
>,-0.00027719614536459184,
>>> current period 3,
>,-0.00026601198207474273,
>>> current period 4,
>,-0.00029351950554519886,
episode 106: ,
overall reward tensor(-0.1596),
overall switching reward tensor(-0.1582),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002905978732625257,
>>> current period 2,
>,-0.00024385219148251517,
>>> current period 3,
>,-0.0002410816020898209,
>>> current period 4,
>,-0.00029534494074726796,
episode 107: ,
overall reward tensor(-0.1316),
overall switching reward tensor(-0.1303),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002565027453712102,
>>> current period 2,
>,-0.000263113141586766,
>>> current period 3,
>,-0.00028870156066773233,
>>> current period 4,
>,-0.0002313196518252381,
episode 108: ,
overall reward tensor(-0.1600),
overall switching reward tensor(-0.1587),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002924026552953107,
>>> current period 2,
>,-0.00025912282332532207,
>>> current period 3,
>,-0.0003424757855739248,
>>> current period 4,
>,-0.00026057409909218174,
episode 109: ,
overall reward tensor(-0.1651),
overall switching reward tensor(-0.1637),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002922643959375078,
>>> current period 2,
>,-0.0002689403882091046,
>>> current period 3,
>,-0.00029722801569989697,
>>> current period 4,
>,-0.00027057941341510544,
episode 110: ,
overall reward tensor(-0.1557),
overall switching reward tensor(-0.1544),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022392005613295043,
>>> current period 2,
>,-0.0002482757627885078,
>>> current period 3,
>,-0.0002470411260411571,
>>> current period 4,
>,-0.0002943640568217303,
episode 111: ,
overall reward tensor(-0.1545),
overall switching reward tensor(-0.1533),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002987658611185818,
>>> current period 2,
>,-0.00023291700066949307,
>>> current period 3,
>,-0.0003232138749072103,
>>> current period 4,
>,-0.00029940189606426606,
episode 112: ,
overall reward tensor(-0.1679),
overall switching reward tensor(-0.1665),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002357690702324983,
>>> current period 2,
>,-0.00022937496781726076,
>>> current period 3,
>,-0.0003175747125705742,
>>> current period 4,
>,-0.0002883382291277855,
episode 113: ,
overall reward tensor(-0.1742),
overall switching reward tensor(-0.1729),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00027719384979326946,
>>> current period 2,
>,-0.00022598883858534818,
>>> current period 3,
>,-0.00025924034439550803,
>>> current period 4,
>,-0.0002772347254624457,
episode 114: ,
overall reward tensor(-0.1666),
overall switching reward tensor(-0.1653),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002378546966688961,
>>> current period 2,
>,-0.0002835234140867722,
>>> current period 3,
>,-0.00027059606574484453,
>>> current period 4,
>,-0.00027010602059796517,
episode 115: ,
overall reward tensor(-0.1712),
overall switching reward tensor(-0.1699),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00027462471325854143,
>>> current period 2,
>,-0.0002536949208486235,
>>> current period 3,
>,-0.0003362253146954171,
>>> current period 4,
>,-0.00026406820483155385,
episode 116: ,
overall reward tensor(-0.1521),
overall switching reward tensor(-0.1508),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023150925201216458,
>>> current period 2,
>,-0.0002487264583836017,
>>> current period 3,
>,-0.0002739790831903815,
>>> current period 4,
>,-0.0002804722651529984,
episode 117: ,
overall reward tensor(-0.1422),
overall switching reward tensor(-0.1409),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000241364993718133,
>>> current period 2,
>,-0.00027776266477102667,
>>> current period 3,
>,-0.00030621552800417216,
>>> current period 4,
>,-0.00026297229572106286,
episode 118: ,
overall reward tensor(-0.1314),
overall switching reward tensor(-0.1301),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022789667246989227,
>>> current period 2,
>,-0.0002597826812450973,
>>> current period 3,
>,-0.00033372148594167377,
>>> current period 4,
>,-0.00024211624999625117,
episode 119: ,
overall reward tensor(-0.1600),
overall switching reward tensor(-0.1587),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002555328436963239,
>>> current period 2,
>,-0.00028206930450478095,
>>> current period 3,
>,-0.0002987838199082902,
>>> current period 4,
>,-0.00023830755499648979,
episode 120: ,
overall reward tensor(-0.1602),
overall switching reward tensor(-0.1589),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002304941786072461,
>>> current period 2,
>,-0.0002719324220473628,
>>> current period 3,
>,-0.0002806016202047638,
>>> current period 4,
>,-0.00027718799561144726,
episode 121: ,
overall reward tensor(-0.1558),
overall switching reward tensor(-0.1545),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028576731125517753,
>>> current period 2,
>,-0.0002867121311841934,
>>> current period 3,
>,-0.00033090956795266076,
>>> current period 4,
>,-0.00024880219942001046,
episode 122: ,
overall reward tensor(-0.1598),
overall switching reward tensor(-0.1584),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022292914700680665,
>>> current period 2,
>,-0.00026732957807129305,
>>> current period 3,
>,-0.0003059024433604618,
>>> current period 4,
>,-0.000223724409049892,
episode 123: ,
overall reward tensor(-0.1532),
overall switching reward tensor(-0.1520),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022596990379855522,
>>> current period 2,
>,-0.00022526378164020884,
>>> current period 3,
>,-0.0002451331238988805,
>>> current period 4,
>,-0.00024260708612815175,
episode 124: ,
overall reward tensor(-0.1525),
overall switching reward tensor(-0.1513),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00030337386800758195,
>>> current period 2,
>,-0.00024034188704225132,
>>> current period 3,
>,-0.00024119224943435361,
>>> current period 4,
>,-0.0002925858622633213,
episode 125: ,
overall reward tensor(-0.1555),
overall switching reward tensor(-0.1542),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026458427066146573,
>>> current period 2,
>,-0.0002539781092193681,
>>> current period 3,
>,-0.0002792158177236103,
>>> current period 4,
>,-0.0002855745254595239,
episode 126: ,
overall reward tensor(-0.1319),
overall switching reward tensor(-0.1306),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002455995245957449,
>>> current period 2,
>,-0.00021951935204798202,
>>> current period 3,
>,-0.00030963604755264586,
>>> current period 4,
>,-0.0002902819389389678,
episode 127: ,
overall reward tensor(-0.1486),
overall switching reward tensor(-0.1473),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000262409928054792,
>>> current period 2,
>,-0.00023663663901784065,
>>> current period 3,
>,-0.00030020085935853743,
>>> current period 4,
>,-0.00028929494705709523,
episode 128: ,
overall reward tensor(-0.1630),
overall switching reward tensor(-0.1617),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002774108609538835,
>>> current period 2,
>,-0.0002750138416755609,
>>> current period 3,
>,-0.00031487789604769066,
>>> current period 4,
>,-0.0002589310275688551,
episode 129: ,
overall reward tensor(-0.1643),
overall switching reward tensor(-0.1630),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028386409674056764,
>>> current period 2,
>,-0.0002678218959959284,
>>> current period 3,
>,-0.0002796756038838914,
>>> current period 4,
>,-0.00028263490402993845,
episode 130: ,
overall reward tensor(-0.1510),
overall switching reward tensor(-0.1497),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002404959897265454,
>>> current period 2,
>,-0.00023766877881861067,
>>> current period 3,
>,-0.0002599936650866696,
>>> current period 4,
>,-0.0002651034354969502,
episode 131: ,
overall reward tensor(-0.1686),
overall switching reward tensor(-0.1674),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003035505001447422,
>>> current period 2,
>,-0.00021483501647356361,
>>> current period 3,
>,-0.00028803197777361154,
>>> current period 4,
>,-0.0002521375962958633,
episode 132: ,
overall reward tensor(-0.1643),
overall switching reward tensor(-0.1630),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024136458473750436,
>>> current period 2,
>,-0.00027429655479459383,
>>> current period 3,
>,-0.00027308953032258176,
>>> current period 4,
>,-0.00029417124537677546,
episode 133: ,
overall reward tensor(-0.1518),
overall switching reward tensor(-0.1504),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026328292180444,
>>> current period 2,
>,-0.00022632954173173962,
>>> current period 3,
>,-0.00030269001774274005,
>>> current period 4,
>,-0.0002673915188604428,
episode 134: ,
overall reward tensor(-0.1703),
overall switching reward tensor(-0.1690),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022497012881294478,
>>> current period 2,
>,-0.0002794158982556119,
>>> current period 3,
>,-0.0002823260248649339,
>>> current period 4,
>,-0.0002373640964859079,
episode 135: ,
overall reward tensor(-0.1574),
overall switching reward tensor(-0.1562),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022106954890820029,
>>> current period 2,
>,-0.0002316596233853336,
>>> current period 3,
>,-0.00025484241688869606,
>>> current period 4,
>,-0.00023260544739692714,
episode 136: ,
overall reward tensor(-0.1757),
overall switching reward tensor(-0.1745),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00030286541745811396,
>>> current period 2,
>,-0.00026736342982683505,
>>> current period 3,
>,-0.00027014522910312916,
>>> current period 4,
>,-0.0002578084254030823,
episode 137: ,
overall reward tensor(-0.1557),
overall switching reward tensor(-0.1544),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028602573597914994,
>>> current period 2,
>,-0.0002769737826674043,
>>> current period 3,
>,-0.0003124449345567628,
>>> current period 4,
>,-0.0002758719672124605,
episode 138: ,
overall reward tensor(-0.1668),
overall switching reward tensor(-0.1654),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002765032853347956,
>>> current period 2,
>,-0.00022568916893645673,
>>> current period 3,
>,-0.0002787474563840502,
>>> current period 4,
>,-0.0002595320011291865,
episode 139: ,
overall reward tensor(-0.1426),
overall switching reward tensor(-0.1413),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00021802888868226734,
>>> current period 2,
>,-0.0002681287519151525,
>>> current period 3,
>,-0.00027681790787940366,
>>> current period 4,
>,-0.0003012498956908772,
episode 140: ,
overall reward tensor(-0.1577),
overall switching reward tensor(-0.1564),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028490664718671326,
>>> current period 2,
>,-0.0002591255116999373,
>>> current period 3,
>,-0.00029988278682826304,
>>> current period 4,
>,-0.00028835406908864637,
episode 141: ,
overall reward tensor(-0.1471),
overall switching reward tensor(-0.1457),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002420161923315836,
>>> current period 2,
>,-0.0002874766081714032,
>>> current period 3,
>,-0.00026730206723095753,
>>> current period 4,
>,-0.0002465739974250857,
episode 142: ,
overall reward tensor(-0.1653),
overall switching reward tensor(-0.1641),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002796951765738717,
>>> current period 2,
>,-0.0002497263155735125,
>>> current period 3,
>,-0.0002681737326018624,
>>> current period 4,
>,-0.0002641683394328549,
episode 143: ,
overall reward tensor(-0.1434),
overall switching reward tensor(-0.1421),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028006051695430266,
>>> current period 2,
>,-0.00026506121946878833,
>>> current period 3,
>,-0.0003124449345567628,
>>> current period 4,
>,-0.0002753775873651373,
episode 144: ,
overall reward tensor(-0.1622),
overall switching reward tensor(-0.1608),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026261195833062666,
>>> current period 2,
>,-0.00026037067392538,
>>> current period 3,
>,-0.0002566949195522633,
>>> current period 4,
>,-0.00029399879656648125,
episode 145: ,
overall reward tensor(-0.1422),
overall switching reward tensor(-0.1409),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00030694058465961793,
>>> current period 2,
>,-0.0002264935587545551,
>>> current period 3,
>,-0.0002724910720639162,
>>> current period 4,
>,-0.00027816834182864495,
episode 146: ,
overall reward tensor(-0.1652),
overall switching reward tensor(-0.1639),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028307205514853617,
>>> current period 2,
>,-0.00023032564158545035,
>>> current period 3,
>,-0.0002613981308592881,
>>> current period 4,
>,-0.00028670571370307033,
episode 147: ,
overall reward tensor(-0.1754),
overall switching reward tensor(-0.1741),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00027764827485484,
>>> current period 2,
>,-0.0002355919587773145,
>>> current period 3,
>,-0.0002692536074019596,
>>> current period 4,
>,-0.0002909782702668219,
episode 148: ,
overall reward tensor(-0.1568),
overall switching reward tensor(-0.1555),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002663711575287538,
>>> current period 2,
>,-0.00028020760707094905,
>>> current period 3,
>,-0.00026568528552052296,
>>> current period 4,
>,-0.0002776965037145973,
episode 149: ,
overall reward tensor(-0.1389),
overall switching reward tensor(-0.1376),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024451200993593137,
>>> current period 2,
>,-0.00026279769925314817,
>>> current period 3,
>,-0.0003558304938144179,
>>> current period 4,
>,-0.000307640862450636,
episode 150: ,
overall reward tensor(-0.1447),
overall switching reward tensor(-0.1433),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023110939123659337,
>>> current period 2,
>,-0.0002751973876318961,
>>> current period 3,
>,-0.00026694462125781865,
>>> current period 4,
>,-0.0002954863238580416,
episode 151: ,
overall reward tensor(-0.1362),
overall switching reward tensor(-0.1349),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028308552106690884,
>>> current period 2,
>,-0.0002607338508251422,
>>> current period 3,
>,-0.00025462441415967537,
>>> current period 4,
>,-0.0002921719913750938,
episode 152: ,
overall reward tensor(-0.1632),
overall switching reward tensor(-0.1619),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022244284003023019,
>>> current period 2,
>,-0.0002579954164994274,
>>> current period 3,
>,-0.00025066293447841833,
>>> current period 4,
>,-0.0002596344131949536,
episode 153: ,
overall reward tensor(-0.1668),
overall switching reward tensor(-0.1656),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023991108908734185,
>>> current period 2,
>,-0.00026687137448518224,
>>> current period 3,
>,-0.00024066577336550872,
>>> current period 4,
>,-0.00024020449737610896,
episode 154: ,
overall reward tensor(-0.1641),
overall switching reward tensor(-0.1628),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024214733117224104,
>>> current period 2,
>,-0.00025302917467424197,
>>> current period 3,
>,-0.00028375226686442494,
>>> current period 4,
>,-0.00025679795269633037,
episode 155: ,
overall reward tensor(-0.1558),
overall switching reward tensor(-0.1546),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024310868120828292,
>>> current period 2,
>,-0.00021483501647356361,
>>> current period 3,
>,-0.00028115731880610725,
>>> current period 4,
>,-0.00029389718690084294,
episode 156: ,
overall reward tensor(-0.1427),
overall switching reward tensor(-0.1414),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003024298362444402,
>>> current period 2,
>,-0.0002429928580944583,
>>> current period 3,
>,-0.0002514790544471633,
>>> current period 4,
>,-0.00029391085320757743,
episode 157: ,
overall reward tensor(-0.1468),
overall switching reward tensor(-0.1455),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000303527774524958,
>>> current period 2,
>,-0.00028196275736222585,
>>> current period 3,
>,-0.00025676010881332757,
>>> current period 4,
>,-0.00025614027649194997,
episode 158: ,
overall reward tensor(-0.1517),
overall switching reward tensor(-0.1503),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022413532001263893,
>>> current period 2,
>,-0.0002497060954376644,
>>> current period 3,
>,-0.000278020064519221,
>>> current period 4,
>,-0.00028946348697500823,
episode 159: ,
overall reward tensor(-0.1574),
overall switching reward tensor(-0.1561),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028079216656101864,
>>> current period 2,
>,-0.00023351537404504478,
>>> current period 3,
>,-0.0002799594691224729,
>>> current period 4,
>,-0.0002804564251921376,
episode 160: ,
overall reward tensor(-0.1725),
overall switching reward tensor(-0.1712),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002750872853913716,
>>> current period 2,
>,-0.00025747473275243365,
>>> current period 3,
>,-0.0002811349033550037,
>>> current period 4,
>,-0.00025811632110029503,
episode 161: ,
overall reward tensor(-0.1499),
overall switching reward tensor(-0.1486),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028894918106133394,
>>> current period 2,
>,-0.00022696534070716634,
>>> current period 3,
>,-0.000276487859615945,
>>> current period 4,
>,-0.0002902950883711585,
episode 162: ,
overall reward tensor(-0.1500),
overall switching reward tensor(-0.1486),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000298236105999532,
>>> current period 2,
>,-0.0002543199172595539,
>>> current period 3,
>,-0.0003123933685602844,
>>> current period 4,
>,-0.00025735601784535506,
episode 163: ,
overall reward tensor(-0.1661),
overall switching reward tensor(-0.1647),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003019803016261348,
>>> current period 2,
>,-0.0002170492628020266,
>>> current period 3,
>,-0.0002707222200543149,
>>> current period 4,
>,-0.0002824311074473389,
episode 164: ,
overall reward tensor(-0.1544),
overall switching reward tensor(-0.1530),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00025472871991211806,
>>> current period 2,
>,-0.0002776439886169763,
>>> current period 3,
>,-0.00028763408018554396,
>>> current period 4,
>,-0.0002842101485007014,
episode 165: ,
overall reward tensor(-0.1492),
overall switching reward tensor(-0.1478),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028514560127506895,
>>> current period 2,
>,-0.00024572361833368454,
>>> current period 3,
>,-0.0002522950564960282,
>>> current period 4,
>,-0.00023186993261003626,
episode 166: ,
overall reward tensor(-0.1628),
overall switching reward tensor(-0.1616),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002922643959375078,
>>> current period 2,
>,-0.00026695722114024296,
>>> current period 3,
>,-0.0002865696988102279,
>>> current period 4,
>,-0.00030791264295529597,
episode 167: ,
overall reward tensor(-0.1485),
overall switching reward tensor(-0.1471),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003078244976320382,
>>> current period 2,
>,-0.00027474484891897033,
>>> current period 3,
>,-0.0002838883515126799,
>>> current period 4,
>,-0.00023155652021469633,
episode 168: ,
overall reward tensor(-0.1592),
overall switching reward tensor(-0.1579),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023749170333385475,
>>> current period 2,
>,-0.000236652396166313,
>>> current period 3,
>,-0.00029451276054563437,
>>> current period 4,
>,-0.00025408581676048594,
episode 169: ,
overall reward tensor(-0.1451),
overall switching reward tensor(-0.1438),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002657071330161751,
>>> current period 2,
>,-0.0002867121315961039,
>>> current period 3,
>,-0.0002590047431536397,
>>> current period 4,
>,-0.0002478593494487711,
episode 170: ,
overall reward tensor(-0.1505),
overall switching reward tensor(-0.1492),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028382327419428424,
>>> current period 2,
>,-0.0002732956083229608,
>>> current period 3,
>,-0.00033023688601717166,
>>> current period 4,
>,-0.0002902819389389678,
episode 171: ,
overall reward tensor(-0.1568),
overall switching reward tensor(-0.1554),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003009997197359793,
>>> current period 2,
>,-0.0002809981195637883,
>>> current period 3,
>,-0.00027233926552774006,
>>> current period 4,
>,-0.00028120794447399587,
episode 172: ,
overall reward tensor(-0.1469),
overall switching reward tensor(-0.1455),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002525118801972102,
>>> current period 2,
>,-0.0002710784288237338,
>>> current period 3,
>,-0.00024533806843071287,
>>> current period 4,
>,-0.00026146473317247655,
episode 173: ,
overall reward tensor(-0.1180),
overall switching reward tensor(-0.1167),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023870815207736656,
>>> current period 2,
>,-0.0002697709550439753,
>>> current period 3,
>,-0.00028703267531117715,
>>> current period 4,
>,-0.00029230476104731876,
episode 174: ,
overall reward tensor(-0.1387),
overall switching reward tensor(-0.1374),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024201527148301938,
>>> current period 2,
>,-0.000244303483012099,
>>> current period 3,
>,-0.00031400429349311414,
>>> current period 4,
>,-0.00029357900778915184,
episode 175: ,
overall reward tensor(-0.1561),
overall switching reward tensor(-0.1547),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002590371388014798,
>>> current period 2,
>,-0.0002685612599348471,
>>> current period 3,
>,-0.0002811349033550037,
>>> current period 4,
>,-0.0002810151635407249,
episode 176: ,
overall reward tensor(-0.1361),
overall switching reward tensor(-0.1348),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026109524612818373,
>>> current period 2,
>,-0.0002257955828662999,
>>> current period 3,
>,-0.0002878502917449515,
>>> current period 4,
>,-0.00029357900778915184,
episode 177: ,
overall reward tensor(-0.1594),
overall switching reward tensor(-0.1581),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000305061865969459,
>>> current period 2,
>,-0.0002202284823325866,
>>> current period 3,
>,-0.0002792375370705517,
>>> current period 4,
>,-0.00029357900778915184,
episode 178: ,
overall reward tensor(-0.1505),
overall switching reward tensor(-0.1491),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00025002695123459693,
>>> current period 2,
>,-0.00025293993975772003,
>>> current period 3,
>,-0.0003272128264683108,
>>> current period 4,
>,-0.00029357900778915184,
episode 179: ,
overall reward tensor(-0.1400),
overall switching reward tensor(-0.1386),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00029456486993808943,
>>> current period 2,
>,-0.0002801404830043269,
>>> current period 3,
>,-0.0002899776947906347,
>>> current period 4,
>,-0.00028929494705709523,
episode 180: ,
overall reward tensor(-0.1422),
overall switching reward tensor(-0.1408),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00029661707039274436,
>>> current period 2,
>,-0.0002596656281152889,
>>> current period 3,
>,-0.00029789263233092147,
>>> current period 4,
>,-0.0002902950883711585,
episode 181: ,
overall reward tensor(-0.1444),
overall switching reward tensor(-0.1430),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002818308612196542,
>>> current period 2,
>,-0.00027429655479459383,
>>> current period 3,
>,-0.0002716780588058432,
>>> current period 4,
>,-0.0002902950883711585,
episode 182: ,
overall reward tensor(-0.1457),
overall switching reward tensor(-0.1443),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002753154702686769,
>>> current period 2,
>,-0.00024240344596631973,
>>> current period 3,
>,-0.00026639274541349146,
>>> current period 4,
>,-0.0002731051776744933,
episode 183: ,
overall reward tensor(-0.1595),
overall switching reward tensor(-0.1582),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00022143856701492643,
>>> current period 2,
>,-0.0002283025463680637,
>>> current period 3,
>,-0.0003398855460006964,
>>> current period 4,
>,-0.00028314683707558096,
episode 184: ,
overall reward tensor(-0.1553),
overall switching reward tensor(-0.1540),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002974330603052649,
>>> current period 2,
>,-0.0002632061126884151,
>>> current period 3,
>,-0.00026357200345231526,
>>> current period 4,
>,-0.00027114311912251985,
episode 185: ,
overall reward tensor(-0.1593),
overall switching reward tensor(-0.1579),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002944879619218609,
>>> current period 2,
>,-0.00023404776120190186,
>>> current period 3,
>,-0.0002508885794996427,
>>> current period 4,
>,-0.00023720406332641852,
episode 186: ,
overall reward tensor(-0.1550),
overall switching reward tensor(-0.1537),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00023874465935254963,
>>> current period 2,
>,-0.0002337741434508525,
>>> current period 3,
>,-0.00034744679910374255,
>>> current period 4,
>,-0.0002321693342889549,
episode 187: ,
overall reward tensor(-0.1602),
overall switching reward tensor(-0.1590),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028386409674056764,
>>> current period 2,
>,-0.00026758364775870177,
>>> current period 3,
>,-0.000281681303802773,
>>> current period 4,
>,-0.00026067138369247224,
episode 188: ,
overall reward tensor(-0.1487),
overall switching reward tensor(-0.1474),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002896606224794082,
>>> current period 2,
>,-0.0002515626723734224,
>>> current period 3,
>,-0.0002776671962139426,
>>> current period 4,
>,-0.00024622687956814965,
episode 189: ,
overall reward tensor(-0.1601),
overall switching reward tensor(-0.1588),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000249047309863859,
>>> current period 2,
>,-0.00027776266477102667,
>>> current period 3,
>,-0.00028786889804504663,
>>> current period 4,
>,-0.00023695273772878338,
episode 190: ,
overall reward tensor(-0.1575),
overall switching reward tensor(-0.1562),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002794675169414078,
>>> current period 2,
>,-0.00027282441727985397,
>>> current period 3,
>,-0.0002543373769446007,
>>> current period 4,
>,-0.00028162154079238133,
episode 191: ,
overall reward tensor(-0.1305),
overall switching reward tensor(-0.1291),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00030283210824627837,
>>> current period 2,
>,-0.00025376651199149303,
>>> current period 3,
>,-0.00028858120639722315,
>>> current period 4,
>,-0.0003065339776698869,
episode 192: ,
overall reward tensor(-0.1453),
overall switching reward tensor(-0.1439),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00026288242586440454,
>>> current period 2,
>,-0.00022849928142826064,
>>> current period 3,
>,-0.0002741666680739964,
>>> current period 4,
>,-0.0002820288945009481,
episode 193: ,
overall reward tensor(-0.1446),
overall switching reward tensor(-0.1434),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002976159081427481,
>>> current period 2,
>,-0.000269332276767401,
>>> current period 3,
>,-0.00029354825006714665,
>>> current period 4,
>,-0.00029090526514783554,
episode 194: ,
overall reward tensor(-0.1576),
overall switching reward tensor(-0.1562),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002198526159374386,
>>> current period 2,
>,-0.00027995639602579873,
>>> current period 3,
>,-0.00027569083672484304,
>>> current period 4,
>,-0.0002690535885117587,
episode 195: ,
overall reward tensor(-0.1551),
overall switching reward tensor(-0.1538),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002931953993177732,
>>> current period 2,
>,-0.00026540115039239387,
>>> current period 3,
>,-0.00024388415175818727,
>>> current period 4,
>,-0.0002912909244256592,
episode 196: ,
overall reward tensor(-0.1318),
overall switching reward tensor(-0.1304),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00030114907771590767,
>>> current period 2,
>,-0.00027105438840184883,
>>> current period 3,
>,-0.00025033680253447885,
>>> current period 4,
>,-0.0002916380471351329,
episode 197: ,
overall reward tensor(-0.1484),
overall switching reward tensor(-0.1471),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00027286041782215447,
>>> current period 2,
>,-0.00025963989564928335,
>>> current period 3,
>,-0.0002959121749576967,
>>> current period 4,
>,-0.0002813470089591505,
episode 198: ,
overall reward tensor(-0.1338),
overall switching reward tensor(-0.1325),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00030014048520701905,
>>> current period 2,
>,-0.0002320752678934383,
>>> current period 3,
>,-0.0003393347693467857,
>>> current period 4,
>,-0.00026146473317247655,
episode 199: ,
overall reward tensor(-0.1506),
overall switching reward tensor(-0.1492),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003078244976320382,
>>> current period 2,
>,-0.0002695459510493734,
>>> current period 3,
>,-0.0003068428574913546,
>>> current period 4,
>,-0.00029230476104731876,
episode 200: ,
overall reward tensor(-0.1318),
overall switching reward tensor(-0.1304),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0003056689714556466,
>>> current period 2,
>,-0.0002737799887531904,
>>> current period 3,
>,-0.00030146318760743336,
>>> current period 4,
>,-0.00028867697822884886,
episode 201: ,
overall reward tensor(-0.1452),
overall switching reward tensor(-0.1438),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00030702382297951816,
>>> current period 2,
>,-0.00028763345045883324,
>>> current period 3,
>,-0.0002522900028711487,
>>> current period 4,
>,-0.0003089069614342336,
episode 202: ,
overall reward tensor(-0.1346),
overall switching reward tensor(-0.1332),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028894918106133394,
>>> current period 2,
>,-0.00027307225643032247,
>>> current period 3,
>,-0.0002490095944243966,
>>> current period 4,
>,-0.0002916380471351329,
episode 203: ,
overall reward tensor(-0.1428),
overall switching reward tensor(-0.1415),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028342347510124604,
>>> current period 2,
>,-0.0002716289797029182,
>>> current period 3,
>,-0.0003137947919317904,
>>> current period 4,
>,-0.0002444823365424029,
episode 204: ,
overall reward tensor(-0.1327),
overall switching reward tensor(-0.1313),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.000309703938400478,
>>> current period 2,
>,-0.00026261140020667986,
>>> current period 3,
>,-0.00029354825006714665,
>>> current period 4,
>,-0.0002916380471351329,
episode 205: ,
overall reward tensor(-0.1370),
overall switching reward tensor(-0.1356),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00024170855358536132,
>>> current period 2,
>,-0.000279692295959378,
>>> current period 3,
>,-0.00030575187200827407,
>>> current period 4,
>,-0.0002753775873651373,
episode 206: ,
overall reward tensor(-0.1305),
overall switching reward tensor(-0.1292),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.00028395609461578914,
>>> current period 2,
>,-0.0002578125889161952,
>>> current period 3,
>,-0.0002522900028711487,
>>> current period 4,
>,-0.0002528097471728707,
episode 207: ,
overall reward tensor(-0.1291),
overall switching reward tensor(-0.1278),
>>> current period 0,
>,-0.0002378839600100482,
>>> current period 1,
>,-0.0002616214817957873,
>>> current period 2,
>,-0.00028206982526321483,
>>> current period 3,
>,-0.0003034489842518337,
>>> current period 4,
>,-0.00026187743374730396,
episode 208: ,
overall reward tensor(-0.1671),
overall switching reward tensor(-0.1657),
>>> current period 0,
