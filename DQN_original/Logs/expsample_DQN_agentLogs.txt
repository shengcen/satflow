>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022295789686567453,
>>> current period 2,
>,-0.0001837827636527342,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.00019033002622011693,
episode 0: ,
overall reward tensor(-0.0646),
overall switching reward tensor(-0.0635),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.00017924909633379964,
episode 1: ,
overall reward tensor(-0.0676),
overall switching reward tensor(-0.0665),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023042707537316784,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00020293813813781293,
>>> current period 4,
>,-0.0001920149939413036,
episode 2: ,
overall reward tensor(-0.0712),
overall switching reward tensor(-0.0701),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002483460889735003,
>>> current period 2,
>,-0.0001837827636527342,
>>> current period 3,
>,-0.00020293813813781293,
>>> current period 4,
>,-0.00019033002622011693,
episode 3: ,
overall reward tensor(-0.0697),
overall switching reward tensor(-0.0686),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00017924909633379964,
episode 4: ,
overall reward tensor(-0.0720),
overall switching reward tensor(-0.0709),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.0001922416352382981,
episode 5: ,
overall reward tensor(-0.0716),
overall switching reward tensor(-0.0705),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023042707537316784,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 6: ,
overall reward tensor(-0.0684),
overall switching reward tensor(-0.0672),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002483460889735003,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00020293813813781293,
>>> current period 4,
>,-0.0001920149939413036,
episode 7: ,
overall reward tensor(-0.0709),
overall switching reward tensor(-0.0698),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 8: ,
overall reward tensor(-0.0574),
overall switching reward tensor(-0.0563),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022295789686567453,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0002174509483970098,
episode 9: ,
overall reward tensor(-0.0638),
overall switching reward tensor(-0.0626),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0002359602525625044,
episode 10: ,
overall reward tensor(-0.0625),
overall switching reward tensor(-0.0613),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023042707537316784,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.0002359602525625044,
episode 11: ,
overall reward tensor(-0.0619),
overall switching reward tensor(-0.0607),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.0001837827636527342,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.00022366330489671422,
episode 12: ,
overall reward tensor(-0.0634),
overall switching reward tensor(-0.0623),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.00022366330489671422,
episode 13: ,
overall reward tensor(-0.0698),
overall switching reward tensor(-0.0687),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0001920149939413036,
episode 14: ,
overall reward tensor(-0.0730),
overall switching reward tensor(-0.0719),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.00019033002622011693,
episode 15: ,
overall reward tensor(-0.0651),
overall switching reward tensor(-0.0639),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021144934919896158,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.00019033002622011693,
episode 16: ,
overall reward tensor(-0.0715),
overall switching reward tensor(-0.0704),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.0002359602525625044,
episode 17: ,
overall reward tensor(-0.0713),
overall switching reward tensor(-0.0701),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0002359602525625044,
episode 18: ,
overall reward tensor(-0.0550),
overall switching reward tensor(-0.0538),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.00018457678222951092,
episode 19: ,
overall reward tensor(-0.0695),
overall switching reward tensor(-0.0684),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.00019033002622011693,
episode 20: ,
overall reward tensor(-0.0657),
overall switching reward tensor(-0.0646),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00017924909633379964,
episode 21: ,
overall reward tensor(-0.0699),
overall switching reward tensor(-0.0688),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0002359602525625044,
episode 22: ,
overall reward tensor(-0.0679),
overall switching reward tensor(-0.0667),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0002359602525625044,
episode 23: ,
overall reward tensor(-0.0568),
overall switching reward tensor(-0.0556),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.00019033002622011693,
episode 24: ,
overall reward tensor(-0.0523),
overall switching reward tensor(-0.0512),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.0002359602525625044,
episode 25: ,
overall reward tensor(-0.0529),
overall switching reward tensor(-0.0518),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018881334944594543,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0002359602525625044,
episode 26: ,
overall reward tensor(-0.0549),
overall switching reward tensor(-0.0537),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023042707537316784,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 27: ,
overall reward tensor(-0.0641),
overall switching reward tensor(-0.0629),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002483460889735003,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 28: ,
overall reward tensor(-0.0576),
overall switching reward tensor(-0.0564),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022295789686567453,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 29: ,
overall reward tensor(-0.0467),
overall switching reward tensor(-0.0455),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 30: ,
overall reward tensor(-0.0498),
overall switching reward tensor(-0.0486),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.0001922416352382981,
episode 31: ,
overall reward tensor(-0.0688),
overall switching reward tensor(-0.0677),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022295789686567453,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.0001922416352382981,
episode 32: ,
overall reward tensor(-0.0676),
overall switching reward tensor(-0.0665),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.0001837827636527342,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001922416352382981,
episode 33: ,
overall reward tensor(-0.0733),
overall switching reward tensor(-0.0722),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.00020293813813781293,
>>> current period 4,
>,-0.0001922416352382981,
episode 34: ,
overall reward tensor(-0.0722),
overall switching reward tensor(-0.0711),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 35: ,
overall reward tensor(-0.0539),
overall switching reward tensor(-0.0528),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018881334944594543,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.0001920149939413036,
episode 36: ,
overall reward tensor(-0.0741),
overall switching reward tensor(-0.0730),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00022311888954523775,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00018457678222951092,
episode 37: ,
overall reward tensor(-0.0660),
overall switching reward tensor(-0.0649),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00017924909633379964,
episode 38: ,
overall reward tensor(-0.0678),
overall switching reward tensor(-0.0667),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00025548385646722763,
>>> current period 4,
>,-0.0002174509483970098,
episode 39: ,
overall reward tensor(-0.0702),
overall switching reward tensor(-0.0690),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001920149939413036,
episode 40: ,
overall reward tensor(-0.0581),
overall switching reward tensor(-0.0570),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018881334944594543,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.00019033002622011693,
episode 41: ,
overall reward tensor(-0.0512),
overall switching reward tensor(-0.0502),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.0002174509483970098,
episode 42: ,
overall reward tensor(-0.0674),
overall switching reward tensor(-0.0663),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.00022366330489671422,
episode 43: ,
overall reward tensor(-0.0642),
overall switching reward tensor(-0.0630),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002483460889735003,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00025548385646722763,
>>> current period 4,
>,-0.0002359602525625044,
episode 44: ,
overall reward tensor(-0.0642),
overall switching reward tensor(-0.0630),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0001920149939413036,
episode 45: ,
overall reward tensor(-0.0534),
overall switching reward tensor(-0.0524),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 46: ,
overall reward tensor(-0.0489),
overall switching reward tensor(-0.0478),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.00022366330489671422,
episode 47: ,
overall reward tensor(-0.0647),
overall switching reward tensor(-0.0635),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0001922416352382981,
episode 48: ,
overall reward tensor(-0.0537),
overall switching reward tensor(-0.0526),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.00019033002622011693,
episode 49: ,
overall reward tensor(-0.0519),
overall switching reward tensor(-0.0508),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 50: ,
overall reward tensor(-0.0498),
overall switching reward tensor(-0.0486),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 51: ,
overall reward tensor(-0.0456),
overall switching reward tensor(-0.0445),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00022366330489671422,
episode 52: ,
overall reward tensor(-0.0601),
overall switching reward tensor(-0.0589),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001922416352382981,
episode 53: ,
overall reward tensor(-0.0609),
overall switching reward tensor(-0.0597),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.00021954790163384967,
>>> current period 4,
>,-0.0001922416352382981,
episode 54: ,
overall reward tensor(-0.0641),
overall switching reward tensor(-0.0630),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0001922416352382981,
episode 55: ,
overall reward tensor(-0.0580),
overall switching reward tensor(-0.0569),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001922416352382981,
episode 56: ,
overall reward tensor(-0.0584),
overall switching reward tensor(-0.0573),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.000204572700187934,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0002359602525625044,
episode 57: ,
overall reward tensor(-0.0560),
overall switching reward tensor(-0.0548),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.0002574180450079951,
>>> current period 4,
>,-0.0001922416352382981,
episode 58: ,
overall reward tensor(-0.0526),
overall switching reward tensor(-0.0514),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0002359602525625044,
episode 59: ,
overall reward tensor(-0.0509),
overall switching reward tensor(-0.0498),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0002359602525625044,
episode 60: ,
overall reward tensor(-0.0517),
overall switching reward tensor(-0.0505),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.0001814064368564347,
>>> current period 3,
>,-0.00021512657793404486,
>>> current period 4,
>,-0.0001922416352382981,
episode 61: ,
overall reward tensor(-0.0568),
overall switching reward tensor(-0.0557),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021386940444094563,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001920149939413036,
episode 62: ,
overall reward tensor(-0.0624),
overall switching reward tensor(-0.0613),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 63: ,
overall reward tensor(-0.0540),
overall switching reward tensor(-0.0528),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00023287244621442716,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.0002354044409338387,
>>> current period 4,
>,-0.0001922416352382981,
episode 64: ,
overall reward tensor(-0.0413),
overall switching reward tensor(-0.0402),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00019823841982852277,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001920149939413036,
episode 65: ,
overall reward tensor(-0.0579),
overall switching reward tensor(-0.0567),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 66: ,
overall reward tensor(-0.0445),
overall switching reward tensor(-0.0434),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.00019033002622011693,
episode 67: ,
overall reward tensor(-0.0505),
overall switching reward tensor(-0.0494),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002483460889735003,
>>> current period 2,
>,-0.00018545449447824323,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 68: ,
overall reward tensor(-0.0479),
overall switching reward tensor(-0.0468),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021340522805558208,
>>> current period 3,
>,-0.00027160828597556246,
>>> current period 4,
>,-0.0001922416352382981,
episode 69: ,
overall reward tensor(-0.0504),
overall switching reward tensor(-0.0493),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.0002010088020845902,
>>> current period 2,
>,-0.00021144934919896158,
>>> current period 3,
>,-0.000248092068286704,
>>> current period 4,
>,-0.0001922416352382981,
episode 70: ,
overall reward tensor(-0.0620),
overall switching reward tensor(-0.0609),
>>> current period 0,
>,-0.00026828711878992394,
>>> current period 1,
>,-0.00020287374964603118,
>>> current period 2,
>,-0.0001814064368564347,
